---
title: "Logging with Grafana Alloy and Loki"
date: 2025-10-24T10:00:00+07:00
draft: false
categories: ["Logging", "Observability"]
tags: ["Grafana", "Alloy", "Loki", "Logging", "Docker"]
description: "A step-by-step guide to setting up a complete, containerized logging stack with Grafana Alloy, Loki, and a log generator using Docker Compose."
---

Grafana Alloy is an open-source telemetry collector from Grafana that merges the best of the Prometheus and OpenTelemetry communities. As the successor to Promtail, Alloy is now the recommended way to send log data to Grafana Loki.

This tutorial provides a comprehensive, step-by-step guide to deploying a fully containerized logging stack using Docker Compose. The stack includes a log-generating application, Grafana Alloy for collection and parsing, Loki for storage, and Grafana for visualization.

<!-- more -->

## Infrastructure Overview

The logging infrastructure we are building consists of four main components, all running as separate containers managed by Docker Compose:

1.  **Log Generator**: A simple service that continuously writes structured JSON logs to a file, simulating a real application.
2.  **Grafana Alloy**: Our telemetry agent. It tails the log file generated by the `log-generator`, parses the JSON content, adds labels, and forwards the logs to Loki.
3.  **Grafana Loki**: The heart of our logging backend. Loki efficiently stores the logs sent by Alloy.
4.  **Grafana**: The visualization layer, pre-configured with Loki as a data source, used to query and view our logs.

This setup creates a robust, isolated, and reproducible pipeline for managing and analyzing logs.

## Why Grafana Alloy Over Promtail?

(This section remains unchanged, explaining the benefits of Alloy over the legacy Promtail agent.)

### Promtail vs. Alloy: A Comparison

| Feature                | Promtail                               | Grafana Alloy                          |
| ---------------------- | -------------------------------------- | -------------------------------------- |
| **Primary Focus**      | Log collection for Loki                | Unified (Logs, Metrics, Traces)        |
| **Data Sources**       | Logs only                              | Logs, Metrics, Traces, Profiles        |
| **Configuration**      | YAML                                   | River (HCL-based)                      |
| **Ecosystem**          | Tightly coupled with Loki              | OpenTelemetry & Prometheus compatible  |
| **Development Status** | Maintenance Mode                       | Active Development                     |
| **Extensibility**      | Limited                                | Highly extensible with components      |

## 1. Project Structure

Before we create the configuration files, let's set up the necessary directory structure for our project. This ensures that all the files are in the right place for Docker Compose to mount them into the containers.

```
. 
├── alloy/
│   └── config.alloy
├── grafana/
│   └── provisioning/
│       └── datasources.yml
├── logs/
├── docker-compose.yml
└── start-log-generator.sh
```

Create these directories and empty files before proceeding.

## 2. Configuration Files

Now, let's populate the files with the required configurations.

### a. Log Generator Script (`start-log-generator.sh`)

This script will run in a loop, generating structured JSON logs with different levels (`info`, `warn`, `error`) and writing them to a file inside the shared `logs` volume.

```bash
#!/bin/bash
mkdir -p /app/logs
while true; do
  echo "{\"time\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\", \"level\": \"info\", \"message\": \"User logged in\", \"user_id\": \"$((RANDOM % 1000))\"}" >> /app/logs/app.log
  echo "{\"time\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\", \"level\": \"warn\", \"message\": \"Disk space is running low\", \"remaining_gb\": \"$((RANDOM % 10))\"}" >> /app/logs/app.log
  echo "{\"time\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\", \"level\": \"error\", \"message\": \"Failed to connect to database\", \"db_host\": \"db.example.com\"}" >> /app/logs/app.log
  sleep 5
done
```

**Important:** Make this script executable by running `chmod +x start-log-generator.sh`.

### b. Alloy Configuration (`alloy/config.alloy`)

This configuration tells Alloy where to find the logs, how to parse them, and where to send them.

```river
loki.source.file "app_logs" {
    targets    = [{"__path__" = "/var/log/app/*.log"}]
    forward_to = [loki.process.parse_json.receiver]
}

loki.process "parse_json" {
    stage.json {
        expressions = {
            "level" = "level",
        }
    }

    stage.labels {
        values = {
            "level" = "",
        }
    }

    forward_to = [loki.write.default.receiver]
}

loki.write "default" {
    endpoint {
        url = "http://loki:3100/loki/api/v1/push"
    }
}
```

### c. Grafana Provisioning (`grafana/provisioning/datasources.yml`)

This file automatically configures Loki as a datasource in Grafana.

```yaml
apiVersion: 1

datasources:
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    isDefault: true
```

### d. Docker Compose (`docker-compose.yml`)

This is the main file that orchestrates all our services.

```yaml
version: "3.8" 

services:
  loki:
    image: grafana/loki:latest
    container_name: loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    environment:
      - LOKI_ANALYTICS_ENABLED=false
    networks:
      - loki-net

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_REPORTING_ENABLED=false
    depends_on:
      - loki
    networks:
      - loki-net

  alloy:
    image: grafana/alloy:latest
    container_name: alloy
    user: root
    ports:
      - "12345:12345"
    volumes:
      - ./alloy/config.alloy:/etc/alloy/config.alloy
      - ./logs:/var/log/app/ 
    command: run /etc/alloy/config.alloy --server.http.listen-addr=0.0.0.0:12345
    environment:
      - ALLOY_REPORTING_ENABLED=false
    depends_on:
      - loki
    networks:
      - loki-net

  log-generator:
    image: ubuntu:latest
    container_name: log-generator
    working_dir: /app
    volumes:
      - ./start-log-generator.sh:/app/start-log-generator.sh
      - ./logs:/app/logs
    command: ["/bin/bash", "start-log-generator.sh"]
    depends_on:
      - alloy
    networks:
      - loki-net

networks:
  loki-net:
    driver: bridge
```

## 3. Running the Stack

With all the files in place, starting the entire logging stack is as simple as running one command from the root of your project directory:

```bash
docker-compose up -d
```

This will download the necessary Docker images and start all four services in the background.

## 4. Dissecting the Docker Compose File

(This section would contain the detailed breakdown of the new docker-compose.yml, explaining each service: `loki`, `grafana`, `alloy`, and `log-generator`, and their respective configurations like volumes, commands, and environment variables.)

## 5. Verify Parsed Logs in Grafana

1.  Open Grafana at `http://localhost:3000` (login with `admin`/`admin`).
2.  Navigate to the **Explore** menu. Loki should be the default data source.
3.  In the "Label browser", you will now see `level` as a selectable label. Click it to see the values `info`, `warn`, and `error`.
4.  Use this LogQL query to filter for only error logs:
    ```logql
    {job="loki.source.file.app_logs", level="error"}
    ```
5.  You will see that Grafana displays the log line and also provides a structured, parsed view of all fields from the original JSON (`message`, `db_host`, etc.), making the logs much easier to read and analyze.

## Conclusion

You have successfully deployed a complete, containerized logging pipeline. This setup provides a powerful foundation for building a robust observability practice, and by using Alloy, you are aligned with the future of telemetry collection in the Grafana ecosystem.